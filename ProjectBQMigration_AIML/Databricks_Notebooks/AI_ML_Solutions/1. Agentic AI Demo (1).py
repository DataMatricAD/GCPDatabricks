# Databricks notebook source
# MAGIC %md
# MAGIC # Agentic AI Demo
# MAGIC
# MAGIC This notebook demonstrates how to build an **Agentic AI-powered data assistant** that:
# MAGIC - Accepts business questions in **natural language**
# MAGIC - Translates them into **SQL queries**
# MAGIC - Executes the SQL on **Databricks SQL Warehouse**
# MAGIC - Displays results in a friendly **Gradio-based UI**
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## Key Components
# MAGIC
# MAGIC ### 1. Library Installation
# MAGIC Installs essential packages:
# MAGIC - `langchain`, `openai`, `databricks-sql-connector` ‚Äì for LLM + Databricks integration
# MAGIC - `gradio` ‚Äì for UI interaction
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 2. Databricks SQL Connection
# MAGIC Defines a utility function to connect to Databricks SQL using credentials stored in `DATABRICKS_CONFIG`. This is used to run SQL queries generated by the AI.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 3. LLM SQL Generator (LangChain + GPT-4)
# MAGIC - Uses `LangChain` and `ChatOpenAI` (`gpt-4`)
# MAGIC - Prompt is tailored to generate SQL against a known schema in `gcp_dbsbq_migration_demo.gold_db`
# MAGIC - Tables used:
# MAGIC   - `gold_customer_features`
# MAGIC   - `gold_daily_store_sales`
# MAGIC   - `gold_inventory_health`
# MAGIC   - `gold_top_products`
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 4. Agent Function: `agentic_ai()`
# MAGIC - Accepts a question (e.g., ‚ÄúWhat was the total revenue last month?‚Äù)
# MAGIC - Uses the LLM to generate valid SQL
# MAGIC - Executes the SQL and returns a Pandas DataFrame
# MAGIC - Handles errors and cleans LLM output
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 5. Gradio UI App
# MAGIC - Web interface built using `gradio.Blocks`
# MAGIC - Users enter a business question
# MAGIC - On submit:
# MAGIC   - The generated SQL is shown
# MAGIC   - The result is displayed as a table
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## Use Cases
# MAGIC - Non-technical users can ask analytics questions directly
# MAGIC - Converts business intent to SQL without manual coding
# MAGIC - Integrates AI + SQL in an interactive, no-code UI
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## Optional / Commented Code
# MAGIC - Simpler interfaces using `gr.Interface`
# MAGIC - Variants of the SQL prompt
# MAGIC - `%sql` cell for direct query testing
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## Summary
# MAGIC This notebook provides a **lightweight, powerful template** to:
# MAGIC - Embed LLMs into analytics workflows
# MAGIC - Enable natural language BI
# MAGIC - Showcase agentic AI patterns using Databricks + OpenAI
# MAGIC
# MAGIC

# COMMAND ----------

# MAGIC %pip install databricks-sql-connector

# COMMAND ----------

# MAGIC %pip install --upgrade langchain langchain-openai langchain-community

# COMMAND ----------

# MAGIC %pip install databricks-sql-connector openai langchain gradio

# COMMAND ----------

dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %run /Workspace/Users/datamatricwithabhijit@gmail.com/ai_util_mod

# COMMAND ----------

import databricks.sql

def run_databricks_query(query: str) -> str:
    try:
        conn = databricks.sql.connect(**DATABRICKS_CONFIG)
        cursor = conn.cursor()
        cursor.execute(query)
        rows = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]
        result = [dict(zip(columns, row)) for row in rows]
        cursor.close()
        conn.close()
        return str(result)
    except Exception as e:
        return f"Error: {str(e)}"


# COMMAND ----------

# from langchain.chat_models import ChatOpenAI
# from langchain.prompts import PromptTemplate
# from langchain.chains import LLMChain

# # Prompt template: translate natural language to SQL
# prompt = PromptTemplate(
#     input_variables=["question"],
#     template="""
# You are an expert data analyst. Convert the user's question into a valid SQL query for a Delta table named `gcp_dbsbq_migration_demo.gold_db.gold_daily_store_sales` with columns:
#   - order_date
#   - store_id
#   - store_name
#   - total_orders
#   - revenue

# User Question: {question}
# SQL Query:
# """)

# llm = ChatOpenAI(temperature=0, model="gpt-4")

# sql_generator = LLMChain(prompt=prompt, llm=llm)


# COMMAND ----------

# from langchain.chat_models import ChatOpenAI
# from langchain.prompts import PromptTemplate
# from langchain.chains import LLMChain

# # Prompt template: translate natural language to SQL
# prompt = PromptTemplate(
#     input_variables=["question"],
#     template="""
# You are an expert data analyst. Convert the user's question into a valid SQL query for the Databricks database `gcp_dbsbq_migration_demo.gold_db`.
# Only use tables that actually exist in this database. If a table or view is not present, do not reference it in your query.
# Assume you can check available tables and columns via information_schema. 
# Write a valid SQL query referencing only existing table(s) in `gcp_dbsbq_migration_demo.gold_db`. Do not reference the `orders` table if it does not exist.

# User Question: {question}
# SQL Query:
# """)

# llm = ChatOpenAI(temperature=0, model="gpt-4")

# sql_generator = LLMChain(prompt=prompt, llm=llm)

# COMMAND ----------

from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
prompt = PromptTemplate(
    input_variables=["question"],
    template="""
You are an expert data analyst.

Convert the user's natural language question into a valid SQL query using the appropriate table(s) from the Databricks database `gcp_dbsbq_migration_demo.gold_db`. Use only the relevant table(s) based on the question.

Here are the available tables and their columns:

1. `gcp_dbsbq_migration_demo.gold_db.gold_customer_features`
   - customer_id
   - first_name
   - last_name
   - total_orders
   - unique_stores_visited
   - lifetime_value
   - avg_order_value
   - first_order_date
   - last_order_date
   - days_since_last_order
   - median_order_value

2. `gcp_dbsbq_migration_demo.gold_db.gold_daily_store_sales`
   - order_date
   - store_id
   - store_name
   - total_orders
   - revenue

3. `gcp_dbsbq_migration_demo.gold_db.gold_inventory_health`
   - store_id
   - store_name
   - product_id
   - product_name
   - stock
   - stock_status

4. `gcp_dbsbq_migration_demo.gold_db.gold_top_products`
   - product_id
   - product_name
   - category
   - total_quantity_sold
   - total_revenue

Return only the raw SQL query (no markdown formatting, no extra commentary, no backticks).

User Question: {question}

SQL Query:
"""
)

llm = ChatOpenAI(temperature=0, model="gpt-4")

sql_generator = LLMChain(prompt=prompt, llm=llm)

# COMMAND ----------

def clean_sql(sql_text: str) -> str:
    # Remove ```sql and ``` or any backticks/markdown artifacts
    return sql_text.strip().replace("```sql", "").replace("```", "").strip()

# COMMAND ----------

def agentic_ai(question: str):
    raw_sql = sql_generator.run(question)
    sql_query = clean_sql(raw_sql)

    print("Generated SQL:", sql_query)
    try:
        conn = databricks.sql.connect(**DATABRICKS_CONFIG)
        cursor = conn.cursor()
        cursor.execute(sql_query)

        rows = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]

        cursor.close()
        conn.close()

        # Return SQL query and tabular result
        return f"**SQL Query:**\n```sql\n{sql_query}\n```", pd.DataFrame(rows, columns=columns)

    except Exception as e:
        return f"**Error:** {str(e)}", pd.DataFrame()


# COMMAND ----------

import gradio as gr
import pandas as pd

with gr.Blocks(theme=gr.themes.Base()) as demo:
    gr.Markdown(
        """
        <h1 style='color:#0066cc; text-align:center;'>üí° Agentic AI: Retail Sales Assistant</h1>
        <p style='text-align:center; font-size: 16px;'>
            Ask questions in plain English about store <b>revenue, orders, or performance</b>.<br>
            Example: <i>"What is the total number of orders?"</i>
        </p>
        """
    )

    with gr.Row():
        with gr.Column(scale=1):
            user_input = gr.Textbox(
                label="Ask a Business Question",
                placeholder="e.g. What was the total revenue last month?",
                lines=2,
                show_label=True
            )
            submit_btn = gr.Button("üí¨ Submit")

        with gr.Column(scale=2):
            sql_output = gr.Markdown(label="üß† SQL Generated")
            table_output = gr.Dataframe(label="üìä Result Table", wrap=True)

    submit_btn.click(
        fn=agentic_ai,
        inputs=user_input,
        outputs=[sql_output, table_output]
    )

demo.launch(share=True)


# COMMAND ----------

# MAGIC %md
# MAGIC # Agentic AI with MCP ‚Äî Jira-Driven Multi-Role Team Orchestration
# MAGIC
# MAGIC This notebook extends your original Agentic AI demo into a **multi-agent system** that:
# MAGIC
# MAGIC - Pulls **tasks from Jira** (backlog ‚Üí in progress ‚Üí done)
# MAGIC - Plans and sequences work
# MAGIC - Assigns to **virtual agents** mapped to team roles:
# MAGIC   - **Data Analyst** ‚Üí NL ‚Üí SQL ‚Üí Databricks SQL Warehouse
# MAGIC   - **Data Engineer** ‚Üí pipelines/jobs/devops
# MAGIC   - **Data Scientist** ‚Üí modeling/experiments (MLflow)
# MAGIC   - **Production Support** ‚Üí monitoring/incident mgmt/rollbacks
# MAGIC - Uses **MCP (Model Context Protocol)** style tools to expose capabilities to the agents (with a local adapter if the `mcp` lib isn't present)
# MAGIC - Offers a **Gradio UI** to trigger runs, preview plans, and watch execution logs
# MAGIC
# MAGIC > Works with your `gcp_dbsbq_migration_demo.gold_db` tables.
# MAGIC
# MAGIC ## Setup
# MAGIC - Fill **Secrets/Widgets** below for Jira + Databricks + LLM keys
# MAGIC - Ensure a **Databricks SQL Warehouse** is available in `DATABRICKS_CONFIG`
# MAGIC - Optional: Use the actual `mcp` Python library if installed; otherwise a **shim adapter** is provided
# MAGIC

# COMMAND ----------



# COMMAND ----------
# MAGIC %pip install -q databricks-sql-connector gradio jira langchain langchain-openai langchain-community pydantic
# MAGIC %pip install -q mlflow
# MAGIC 
# MAGIC # Optional (if you want LangGraph planning)
# MAGIC # %pip install -q langgraph

# COMMAND ----------
import os, json, time, uuid, traceback
from typing import Dict, Any, List, Optional, Callable

import pandas as pd
import databricks.sql
import mlflow

# LangChain (keep consistent with your original)
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain

# Jira client
try:
    from jira import JIRA
except Exception:
    JIRA = None

# Try to import MCP. If missing, use a minimal shim so code still runs.
try:
    import mcp  # type: ignore
    MCP_AVAILABLE = True
except Exception:
    MCP_AVAILABLE = False

# COMMAND ----------
# MAGIC %md
# MAGIC ## Configuration (Secrets/Widgets)
# MAGIC Provide your connection details. Prefer **Databricks secrets** in production.

# COMMAND ----------
# Databricks Widgets (optional UI in notebook)
dbutils.widgets.text("JIRA_URL", "")
dbutils.widgets.text("JIRA_USER", "")
dbutils.widgets.text("JIRA_TOKEN", "")
dbutils.widgets.text("JIRA_JQL", "project = RETAIL AND status = 'To Do' ORDER BY priority DESC, created ASC")

# Example: set in cluster environment / secrets beforehand
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# DATABRICKS_CONFIG expected in /Workspace/.../ai_util_mod you already %run; else define here.
try:
    _ = DATABRICKS_CONFIG  # from your existing util
except NameError:
    DATABRICKS_CONFIG = {
        "server_hostname": os.getenv("DB_SERVER_HOSTNAME", ""),
        "http_path": os.getenv("DB_HTTP_PATH", ""),
        "access_token": os.getenv("DB_ACCESS_TOKEN", ""),
    }

JIRA_CONFIG = {
    "server": dbutils.widgets.get("JIRA_URL"),
    "basic_auth": (dbutils.widgets.get("JIRA_USER"), dbutils.widgets.get("JIRA_TOKEN")),
    "jql": dbutils.widgets.get("JIRA_JQL"),
}

# Validate minimal configuration
def _require_keys(cfg: Dict[str, str], keys: List[str], name: str):
    missing = [k for k in keys if not cfg.get(k)]
    if missing:
        raise ValueError(f"Missing {name} keys: {missing}")

_require_keys(DATABRICKS_CONFIG, ["server_hostname", "http_path", "access_token"], "DATABRICKS_CONFIG")
if JIRA is not None:
    _require_keys(JIRA_CONFIG, ["server"], "JIRA_CONFIG")

# COMMAND ----------
# MAGIC %md
# MAGIC ## Shared Utilities

# COMMAND ----------
def run_databricks_query(query: str) -> pd.DataFrame:
    """Execute SQL on Databricks and return a DataFrame."""
    conn = databricks.sql.connect(**DATABRICKS_CONFIG)
    try:
        cur = conn.cursor()
        cur.execute(query)
        rows = cur.fetchall()
        cols = [d[0] for d in cur.description]
        return pd.DataFrame(rows, columns=cols)
    finally:
        cur.close(); conn.close()


def log(msg: str, store: Optional[List[str]] = None):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{ts}] {msg}"
    print(line)
    if store is not None:
        store.append(line)


# Simple state object for one task run
class RunState:
    def __init__(self, issue_key: str):
        self.issue_key = issue_key
        self.plan: List[str] = []
        self.logs: List[str] = []
        self.artifacts: Dict[str, Any] = {}
        self.status: str = "created"

# COMMAND ----------
# MAGIC %md
# MAGIC ## üîß MCP Adapter (Shim)
# MAGIC If the `mcp` library is present, you can wire real MCP tools. Otherwise we expose a local registry with the same spirit.

# COMMAND ----------
class MCPAdapter:
    def __init__(self):
        self.tools: Dict[str, Callable[..., Any]] = {}

    def register_tool(self, name: str, fn: Callable[..., Any]):
        self.tools[name] = fn

    def call(self, name: str, **kwargs):
        if name not in self.tools:
            raise ValueError(f"Tool not found: {name}")
        return self.tools[name](**kwargs)

mcp_adapter = MCPAdapter()

# COMMAND ----------
# MAGIC %md
# MAGIC ## Register Tools (exposed via MCP adapter)

# COMMAND ----------
# Tool: Databricks SQL

def tool_sql(query: str) -> Dict[str, Any]:
    df = run_databricks_query(query)
    return {"rows": df.to_dict(orient="records"), "columns": list(df.columns)}

mcp_adapter.register_tool("databricks_sql.query", tool_sql)


# Tool: Data Quality ‚Äî basic expectation (count > 0)

def tool_expect_nonempty(query: str) -> Dict[str, Any]:
    df = run_databricks_query(query)
    return {"ok": len(df) > 0, "row_count": len(df)}

mcp_adapter.register_tool("dq.expect_nonempty", tool_expect_nonempty)


# Tool: ML Training (logs to MLflow)

def tool_ml_train(experiment_name: str, run_name: str, training_sql: str, target_col: str) -> Dict[str, Any]:
    mlflow.set_experiment(experiment_name)
    with mlflow.start_run(run_name=run_name) as run:
        df = run_databricks_query(training_sql)
        # Minimal example: compute a baseline metric (e.g., mean of target)
        if target_col not in df.columns:
            raise ValueError(f"target_col {target_col} not in data")
        baseline = float(pd.to_numeric(df[target_col], errors='coerce').mean())
        mlflow.log_metric("baseline_mean", baseline)
        mlflow.log_param("rows", len(df))
        mlflow.log_param("columns", ",".join(df.columns))
        artifact_path = f"/dbfs/tmp/{uuid.uuid4().hex}.csv"
        df.to_csv(artifact_path, index=False)
        mlflow.log_artifact(artifact_path)
        return {"run_id": run.info.run_id, "experiment_id": run.info.experiment_id, "baseline_mean": baseline}

mcp_adapter.register_tool("ml.train_baseline", tool_ml_train)


# Tool: Ops ‚Äî Create/Update a Databricks Job via REST (stub)
import requests

def _db_rest(path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    url = f"https://{DATABRICKS_CONFIG['server_hostname']}/api/2.1/{path}"
    headers = {"Authorization": f"Bearer {DATABRICKS_CONFIG['access_token']}", "Content-Type": "application/json"}
    resp = requests.post(url, headers=headers, data=json.dumps(payload))
    if resp.status_code >= 300:
        raise RuntimeError(f"REST {path} failed: {resp.status_code} {resp.text}")
    return resp.json()


def tool_ops_create_job(name: str, task_notebook_path: str, schedule_cron: Optional[str] = None) -> Dict[str, Any]:
    payload = {
        "name": name,
        "tasks": [
            {"task_key": "main", "notebook_task": {"notebook_path": task_notebook_path}, "job_cluster_key": "j1"}
        ],
        "job_clusters": [
            {"job_cluster_key": "j1", "new_cluster": {"spark_version": "13.3.x-scala2.12", "num_workers": 1}}
        ],
    }
    if schedule_cron:
        payload["schedule"] = {"quartz_cron_expression": schedule_cron, "timezone_id": "UTC"}
    return _db_rest("jobs/create", payload)

mcp_adapter.register_tool("ops.create_job", tool_ops_create_job)


# Tool: Monitoring ‚Äî simple query against a gold table to simulate health check

def tool_monitor_health() -> Dict[str, Any]:
    df = run_databricks_query("""
        SELECT count(*) AS rows FROM gcp_dbsbq_migration_demo.gold_db.gold_daily_store_sales
    """)
    return {"ok": int(df.iloc[0]["rows"]) > 0, "rows": int(df.iloc[0]["rows"]) }

mcp_adapter.register_tool("ops.monitor_health", tool_monitor_health)

# COMMAND ----------
# MAGIC %md
# MAGIC ## Agents
# MAGIC Each agent consumes a `RunState`, uses MCP tools, and appends logs/artifacts.

# COMMAND ----------
# Data Analyst ‚Äî NL ‚Üí SQL ‚Üí DataFrame
sql_prompt = PromptTemplate(
    input_variables=["question"],
    template="""
You are an expert data analyst.

Convert the user's natural language question into a valid SQL query using the appropriate table(s) from the Databricks database `gcp_dbsbq_migration_demo.gold_db`.
Use only these tables and columns:

1. gcp_dbsbq_migration_demo.gold_db.gold_customer_features(
   customer_id, first_name, last_name, total_orders, unique_stores_visited, lifetime_value,
   avg_order_value, first_order_date, last_order_date, days_since_last_order, median_order_value)

2. gcp_dbsbq_migration_demo.gold_db.gold_daily_store_sales(
   order_date, store_id, store_name, total_orders, revenue)

3. gcp_dbsbq_migration_demo.gold_db.gold_inventory_health(
   store_id, store_name, product_id, product_name, stock, stock_status)

4. gcp_dbsbq_migration_demo.gold_db.gold_top_products(
   product_id, product_name, category, total_quantity_sold, total_revenue)

Return only the raw SQL query (no extra commentary/backticks).

User Question: {question}
SQL:
"""
)

llm = ChatOpenAI(temperature=0, model="gpt-4o-mini")
analyst_chain = LLMChain(prompt=sql_prompt, llm=llm)


def agent_data_analyst(state: RunState, question: str):
    log("[Analyst] Generating SQL", state.logs)
    raw = analyst_chain.run(question)
    sql = raw.strip().replace("```sql", "").replace("```", "").strip()
    state.artifacts["analyst.sql"] = sql
    log(f"[Analyst] SQL: {sql}", state.logs)
    res = mcp_adapter.call("databricks_sql.query", query=sql)
    state.artifacts["analyst.result"] = res
    log(f"[Analyst] Returned {len(res['rows'])} rows", state.logs)

# Data Engineer ‚Äî create/update jobs or run ops tools

def agent_data_engineer(state: RunState, job_name: str, notebook_path: str):
    log("[DE] Creating Databricks Job", state.logs)
    try:
        out = mcp_adapter.call("ops.create_job", name=job_name, task_notebook_path=notebook_path)
        state.artifacts["de.job_create"] = out
        log(f"[DE] Job created: {out}", state.logs)
    except Exception as e:
        log(f"[DE] Job create failed: {e}", state.logs)
        raise

# Data Scientist ‚Äî minimal training with MLflow

def agent_data_scientist(state: RunState, experiment: str, train_sql: str, target_col: str):
    log("[DS] Training baseline model", state.logs)
    out = mcp_adapter.call(
        "ml.train_baseline", experiment_name=experiment, run_name=f"baseline-{uuid.uuid4().hex[:6]}",
        training_sql=train_sql, target_col=target_col
    )
    state.artifacts["ds.training_run"] = out
    log(f"[DS] MLflow run: {out}", state.logs)

# Production Support ‚Äî health checks

def agent_prod_support(state: RunState):
    log("[Prod] Running health check", state.logs)
    out = mcp_adapter.call("ops.monitor_health")
    state.artifacts["prod.health"] = out
    log(f"[Prod] Health: {out}", state.logs)

# COMMAND ----------
# MAGIC %md
# MAGIC ## üìã Jira Intake & Planning

# COMMAND ----------
def jira_client() -> Optional[JIRA]:
    if JIRA is None:
        log("Jira library not installed; running in mock mode")
        return None
    return JIRA(server=JIRA_CONFIG["server"], basic_auth=JIRA_CONFIG.get("basic_auth"))


def fetch_next_issue(jql: str) -> Dict[str, Any]:
    client = jira_client()
    if client is None:
        # Mock issue for demo
        return {"key": "DEMO-1", "summary": "Analyze revenue trend last month", "labels": ["analyst"], "type": "Task"}
    issues = client.search_issues(jql, maxResults=1)
    if not issues:
        raise ValueError("No Jira issues found for the JQL")
    i = issues[0]
    return {
        "key": i.key,
        "summary": i.fields.summary,
        "labels": list(i.fields.labels or []),
        "type": i.fields.issuetype.name,
    }


def plan_for_issue(issue: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Create a simple ordered plan based on labels/type. Extend as needed."""
    summary = issue.get("summary", "").lower()
    labels = [l.lower() for l in issue.get("labels", [])]

    steps: List[Dict[str, Any]] = []

    # Always start with Prod health check
    steps.append({"role": "prod_support", "action": "health_check"})

    if "model" in summary or "predict" in summary or "ds" in labels:
        steps.append({"role": "data_scientist", "action": "train", "params": {
            "experiment": "/Shared/experiments/retail-baseline",
            "train_sql": "SELECT total_orders as y, avg_order_value, lifetime_value FROM gcp_dbsbq_migration_demo.gold_db.gold_customer_features",
            "target_col": "y"
        }})

    if "pipeline" in summary or "deploy" in summary or "de" in labels or "engineer" in summary:
        steps.append({"role": "data_engineer", "action": "create_job", "params": {
            "job_name": f"RetailJob-{uuid.uuid4().hex[:6]}",
            "notebook_path": "/Repos/retail/pipelines/gold_refresh"
        }})

    # Default analyst step if it's an analysis request
    if ("revenue" in summary or "orders" in summary) or ("analyst" in labels):
        steps.append({"role": "data_analyst", "action": "sql", "params": {
            "question": "What was the total revenue last month by store?"
        }})

    return steps

# COMMAND ----------
# MAGIC %md
# MAGIC ## üïπÔ∏è Orchestrator

# COMMAND ----------
class Orchestrator:
    def __init__(self):
        self.history: List[RunState] = []

    def run_issue(self, issue: Dict[str, Any]) -> RunState:
        state = RunState(issue_key=issue["key"])
        log(f"[Orch] Starting issue {issue['key']}: {issue['summary']}", state.logs)
        plan = plan_for_issue(issue)
        state.plan = [json.dumps(s) for s in plan]
        state.status = "planned"
        for step in plan:
            try:
                role = step["role"]
                action = step["action"]
                params = step.get("params", {})
                if role == "data_analyst" and action == "sql":
                    agent_data_analyst(state, **params)
                elif role == "data_engineer" and action == "create_job":
                    agent_data_engineer(state, **params)
                elif role == "data_scientist" and action == "train":
                    agent_data_scientist(state, **params)
                elif role == "prod_support" and action == "health_check":
                    agent_prod_support(state)
                else:
                    log(f"[Orch] Unknown step: {step}", state.logs)
            except Exception as e:
                log(f"[Orch] Step failed: {e}\n{traceback.format_exc()}", state.logs)
                state.status = "failed"
                break
        if state.status != "failed":
            state.status = "completed"
            log("[Orch] All steps completed", state.logs)
        self.history.append(state)
        return state

orchestrator = Orchestrator()

# COMMAND ----------
# MAGIC %md
# MAGIC ## üåê Gradio UI

# COMMAND ----------
import gradio as gr

def ui_fetch_and_run(jql: str):
    issue = fetch_next_issue(jql)
    state = orchestrator.run_issue(issue)
    # Pretty returns
    return (
        f"**Issue:** {issue['key']} ‚Äî {issue['summary']}",
        pd.DataFrame({"plan": state.plan}),
        "\n".join(state.logs),
        json.dumps(state.artifacts, indent=2)
    )

with gr.Blocks(theme=gr.themes.Base()) as app:
    gr.Markdown("""
    <h1 style='text-align:center;'>üèóÔ∏è Jira ‚Üí Agentic AI Orchestrator (MCP Tools)</h1>
    <p style='text-align:center;'>Pick the next Jira task via JQL, auto‚Äëplan, and run through Analyst ‚Üí DE ‚Üí DS ‚Üí Prod Support.</p>
    """)
    jql_in = gr.Textbox(label="Jira JQL", value=JIRA_CONFIG["jql"], lines=1)
    run_btn = gr.Button("Fetch Next & Run")

    issue_md = gr.Markdown()
    plan_df = gr.Dataframe(headers=["plan"], label="Planned Steps")
    logs_md = gr.Markdown(label="Execution Logs")
    artifacts_md = gr.Code(label="Artifacts (JSON)")

    run_btn.click(fn=ui_fetch_and_run, inputs=jql_in, outputs=[issue_md, plan_df, logs_md, artifacts_md])

# Comment the next line if you run headless or prefer manual .launch()
app.launch(share=False)

# COMMAND ----------
# MAGIC %md
# MAGIC ## Usage Notes
# MAGIC - Configure **Jira URL / user / token** via widgets or secrets
# MAGIC - Ensure **OPENAI_API_KEY** is in env for `ChatOpenAI`
# MAGIC - Update the **Data Engineer** notebook path used for job creation
# MAGIC - Swap `gpt-4o-mini` for your preferred model
# MAGIC - Extend `plan_for_issue()` with richer routing (issue type, components, custom fields)
# MAGIC - Replace the ML baseline with real training 
# MAGIC - Replace `ops.create_job` stub with a full job JSON matching your infra standards
# MAGIC 
# MAGIC ---
# MAGIC ### What makes this "MCP"?
# MAGIC We expose discrete capabilities (SQL, DQ, ML, Ops, Monitoring) as **tools** and access them via a **tool registry** (`MCPAdapter`).
# MAGIC If you install real **MCP servers/clients**, swap the adapter‚Äôs `register_tool`/`call` with your MCP client bindings ‚Äî the agent code remains the same.
# MAGIC 
# MAGIC ---
# MAGIC ### Quick Smoke Tests
# MAGIC - Change the Jira JQL to a mock and run. Confirm plan ‚Üí logs ‚Üí artifacts.
# MAGIC - In **Artifacts JSON**, check:
# MAGIC   - `analyst.sql` / `analyst.result`
# MAGIC   - `ds.training_run`
# MAGIC   - `de.job_create` (if REST creds/permissions are correct)
# MAGIC   - `prod.health`
# MAGIC 
# MAGIC ---
# MAGIC **End of Notebook**


# COMMAND ----------

# %sql
# SELECT SUM(total_orders) FROM gcp_dbsbq_migration_demo.gold_db.gold_daily_store_sales;

# COMMAND ----------

# import gradio as gr

# with gr.Blocks(theme=gr.themes.Base()) as demo:
#     gr.Markdown(
#         """
#         <h1 style='color:#0066cc; text-align:center;'>üí° Agentic AI: Retail Sales Assistant</h1>
#         <p style='text-align:center; font-size: 16px;'>
#             Ask questions in plain English about store <b>revenue, orders, or performance</b>.<br>
#             Example: <i>"What is the total number of orders?"</i>
#         </p>
#         """
#     )

#     with gr.Row():
#         with gr.Column(scale=1):
#             user_input = gr.Textbox(
#                 label="Ask a Business Question",
#                 placeholder="e.g. What was the total revenue last month?",
#                 lines=2,
#                 show_label=True
#             )
#             submit_btn = gr.Button("üí¨ Submit")

#         with gr.Column(scale=2):
#             output = gr.Markdown(label="üìä AI Response")

#     def respond_to_query(question):
#         return agentic_ai(question)

#     submit_btn.click(fn=respond_to_query, inputs=user_input, outputs=output)

# demo.launch(share=True)


# COMMAND ----------

# import gradio as gr

# gr.Interface(
#     fn=agentic_ai,
#     inputs="text",
#     outputs="markdown",
#     title="Agentic AI: Retail Sales Assistant",
#     description="Ask questions about store revenue, orders, and performance."
# ).launch(share=True)


# COMMAND ----------

# Databricks notebook cell
# %pip install langchain openai langchain-experimental


# COMMAND ----------

# def agentic_ai(query: str) -> str:
#     sql_query = sql_generator.run(query)
#     print("Generated SQL:", sql_query)
#     result = run_databricks_query(sql_query)
#     return f"**Question**: {query}\n\n**SQL**: {sql_query}\n\n**Result**: {result}"


# COMMAND ----------

# def agentic_ai(query: str) -> str:
#     raw_sql = sql_generator.run(query)
#     sql_query = clean_sql(raw_sql)
    
#     print("Generated SQL:", sql_query)
#     result = run_databricks_query(sql_query)
    
#     return f"**Question**: {query}\n\n**SQL**:\n```sql\n{sql_query}\n```\n\n**Result**: {result}"